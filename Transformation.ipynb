{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80c7e8b0",
   "metadata": {},
   "source": [
    "# yo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da77223",
   "metadata": {},
   "source": [
    "One of the approach for solving the problem statements which were:\n",
    "1. Problem Transformation:\n",
    "These approaches involve transforming a multi-label classification problem into a\n",
    "variant or series of single-label problems.\n",
    "Eg- Binary Relevance, Label Powersets, Classification Chains to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d53c5c4",
   "metadata": {},
   "source": [
    "Let us import all the libraries which are required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cfee92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a87df2b",
   "metadata": {},
   "source": [
    "# importing\n",
    "the dataset , which was merged into one , to make my work easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52542917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>Imprisoned in the 1940s for the double murder ...</td>\n",
       "      <td>[18, 80]</td>\n",
       "      <td>['Drama', 'Crime']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>Spanning the years 1945 to 1955, a chronicle o...</td>\n",
       "      <td>[18, 80]</td>\n",
       "      <td>['Drama', 'Crime']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>In the continuing saga of the Corleone crime f...</td>\n",
       "      <td>[18, 80]</td>\n",
       "      <td>['Drama', 'Crime']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>The true story of how businessman Oskar Schind...</td>\n",
       "      <td>[18, 36, 10752]</td>\n",
       "      <td>['Drama', 'History', 'War']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>The defense and the prosecution have rested an...</td>\n",
       "      <td>[18]</td>\n",
       "      <td>['Drama']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "0  The Shawshank Redemption   \n",
       "1             The Godfather   \n",
       "2     The Godfather Part II   \n",
       "3          Schindler's List   \n",
       "4              12 Angry Men   \n",
       "\n",
       "                                            overview        genre_ids  \\\n",
       "0  Imprisoned in the 1940s for the double murder ...         [18, 80]   \n",
       "1  Spanning the years 1945 to 1955, a chronicle o...         [18, 80]   \n",
       "2  In the continuing saga of the Corleone crime f...         [18, 80]   \n",
       "3  The true story of how businessman Oskar Schind...  [18, 36, 10752]   \n",
       "4  The defense and the prosecution have rested an...             [18]   \n",
       "\n",
       "                        genres  \n",
       "0           ['Drama', 'Crime']  \n",
       "1           ['Drama', 'Crime']  \n",
       "2           ['Drama', 'Crime']  \n",
       "3  ['Drama', 'History', 'War']  \n",
       "4                    ['Drama']  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\RKT\\CODE\\python\\projects\\assignment\\Data\\final_movie_genre_v2.csv\")\n",
    "# Display first few rows\n",
    "print(\"Original Data:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6418a4ab",
   "metadata": {},
   "source": [
    "Well weLL we dont need overview as well as genre ids , we are gonna drop em "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e35ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['overview'])\n",
    "#string to list\n",
    "df['genres_list'] = df['genres'].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e3544f",
   "metadata": {},
   "source": [
    "we are using multilabelbinarizer , well in smple words , think of it as a one hot encoding but with multiple winners of a independent variable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9fae1308",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df['genres_list'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ae18a",
   "metadata": {},
   "source": [
    "the exportion of this MultiLabelBinarizer was done later (below is the code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0212224c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlb_classes.pkl']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(mlb, 'mlb_classes.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b363e052",
   "metadata": {},
   "source": [
    "lets get the unique number of genres we have on our hand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9db7dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Classes (18): ['Action' 'Adventure' 'Animation' 'Comedy' 'Crime' 'Drama' 'Family'\n",
      " 'Fantasy' 'History' 'Horror' 'Music' 'Mystery' 'Romance'\n",
      " 'Science Fiction' 'TV Movie' 'Thriller' 'War' 'Western']\n",
      "Shape of Y: (9999, 18)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nUnique Classes ({len(mlb.classes_)}): {mlb.classes_}\")\n",
    "print(f\"Shape of Y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e2fb2",
   "metadata": {},
   "source": [
    "Vectorizer , cuz of course the machine cant understand words and we also need to give importance score to words ,rather than\n",
    "converts a collection of raw documents into a numerical matrix based on word importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "07f82744",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=10000, stop_words='english')\n",
    "X = tfidf.fit_transform(df['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbc8588",
   "metadata": {},
   "source": [
    "similarly \n",
    "the exportion of this vectorizer  was done later (below is the code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3195cbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "822d6070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (9999, 7126)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of X: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a128c427",
   "metadata": {},
   "source": [
    "our traintest slpit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc9316a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb65616",
   "metadata": {},
   "source": [
    "well we are gonna go for binary relevance and logistics regression \n",
    "binary relevance  in simple one , will say like , \"Hey are you action\" yes or no .........hey are you drama yes or no ...\n",
    "goin to each genre one by one \n",
    " \n",
    "\n",
    " for logistics regresison it give me a prbabilities for the classes and well it is fast as compared training a NN \n",
    " and loooking the dataset , this was the first algo came to my mind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "462f79cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "br_lr = OneVsRestClassifier(\n",
    "    LogisticRegression(\n",
    "        solver=\"liblinear\",max_iter=100\n",
    "    )\n",
    ")\n",
    "\n",
    "br_lr.fit(X_train, y_train)\n",
    "y_pred_br_lr = br_lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706b4805",
   "metadata": {},
   "source": [
    "The evaluation ,as usual , but heres the catch , weneed hamming loss to be lowered and sub accuracy to be higee, based ont this ,we weill mostly desgin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "590070d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Relevance + Logistic Regression\n",
      "Hamming Loss: 0.1366388888888889\n",
      "Micro F1: 0.22180034804619522\n",
      "Macro F1: 0.10346711997922431\n",
      "Exact Match Accuracy: 0.0455\n"
     ]
    }
   ],
   "source": [
    "print(\"Binary Relevance + Logistic Regression\")\n",
    "print(\"Hamming Loss:\", hamming_loss(y_test, y_pred_br_lr))\n",
    "print(\"Micro F1:\", f1_score(y_test, y_pred_br_lr, average=\"micro\"))\n",
    "print(\"Macro F1:\", f1_score(y_test, y_pred_br_lr, average=\"macro\"))\n",
    "print(\"Exact Match Accuracy:\", accuracy_score(y_test, y_pred_br_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805861f",
   "metadata": {},
   "source": [
    "# ML FLow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bc3ac9",
   "metadata": {},
   "source": [
    "this was kinda new to me , it took me a time to learn , thank you for this , i got to learn to implement it \n",
    "\n",
    "we are logging the model, its parameters and its metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b98e4687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Boondi ka Ladoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Boondi ka Ladoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "2026/02/10 21:03:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\Boondi ka Ladoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlflow\\models\\model.py:1209: FutureWarning: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization.The recommended safe alternative is the 'skops' format.\n",
      "  flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n",
      "Successfully registered model 'LogisticRegressionModelBinaryReL'.\n",
      "2026/02/10 21:03:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LogisticRegressionModelBinaryReL, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run Logistic_Regression_and binary_relevance at: http://127.0.0.1:5000/#/experiments/809687645743597975/runs/c7933f8ccbf84c8e837f5f951e8ab506\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/809687645743597975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'LogisticRegressionModelBinaryReL'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"movie_predictor_V2\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Logistic_Regression_and binary_relevance\"):\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred_br_lr)\n",
    "    report = classification_report(y_test, y_pred_br_lr, output_dict=True)\n",
    "\n",
    "    mlflow.log_params({\"solver\": \"liblinear\", \"max_iter\": 100})\n",
    "\n",
    "\n",
    "    #   metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"accuracy\": acc,\n",
    "        \"recall_class_0\": report[\"0\"][\"recall\"],\n",
    "        \"recall_class_1\": report[\"1\"][\"recall\"],\n",
    "        \"f1_macro\": report[\"macro avg\"][\"f1-score\"]\n",
    "    })\n",
    "  \n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=br_lr,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"LogisticRegressionModelBinaryReL\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3a8c54",
   "metadata": {},
   "source": [
    "# lets get to another method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0607a0e5",
   "metadata": {},
   "source": [
    "classification chain and linear svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb391582",
   "metadata": {},
   "source": [
    "Classification chain , lets call it CC , it removes the bad thing that was about binary rrelevance , which was ignoring the relationship betweent the classes , for example a movie can be action and adventourus , "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca369a9",
   "metadata": {},
   "source": [
    "SVMs are famous for handling a huge number of features without getting \"confused\" or slowing down as much as other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e49cf53",
   "metadata": {},
   "source": [
    "it is better for multilabel text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e8176a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "base_svm = LinearSVC()\n",
    "\n",
    "chain_svm = ClassifierChain(base_svm)\n",
    "chain_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_chain_svm = chain_svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "24499a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier Chain + Linear SVM\n",
      "Hamming Loss: 0.13747222222222222\n",
      "Micro F1: 0.4419889502762431\n",
      "Macro F1: 0.31386890632982456\n",
      "Exact Match Accuracy: 0.1055\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassifier Chain + Linear SVM\")\n",
    "print(\"Hamming Loss:\", hamming_loss(y_test, y_pred_chain_svm))\n",
    "print(\"Micro F1:\", f1_score(y_test, y_pred_chain_svm, average=\"micro\"))\n",
    "print(\"Macro F1:\", f1_score(y_test, y_pred_chain_svm, average=\"macro\"))\n",
    "print(\"Exact Match Accuracy:\", accuracy_score(y_test, y_pred_chain_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd3fe7",
   "metadata": {},
   "source": [
    "this was kinda new to me , it took me a time to learn , thank you for this , i got to learn to implement it \n",
    "\n",
    "we are logging the model, its parameters and its metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6b054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Boondi ka Ladoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "2026/02/10 21:04:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\Boondi ka Ladoo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlflow\\models\\model.py:1209: FutureWarning: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization.The recommended safe alternative is the 'skops' format.\n",
      "  flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n",
      "Successfully registered model 'ClassificationchainandlinearSVM'.\n",
      "2026/02/10 21:04:40 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ClassificationchainandlinearSVM, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run Classification chain and linearSVM at: http://127.0.0.1:5000/#/experiments/809687645743597975/runs/fb2d214478cc4241b519736cf87418a8\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/809687645743597975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'ClassificationchainandlinearSVM'.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"movie_predictor_V2\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Classification chain and linearSVM\"):\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred_chain_svm)\n",
    "    report = classification_report(y_test, y_pred_chain_svm, output_dict=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #   metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"accuracy\": acc,\n",
    "        \"recall_class_0\": report[\"0\"][\"recall\"],\n",
    "        \"recall_class_1\": report[\"1\"][\"recall\"],\n",
    "        \"f1_macro\": report[\"macro avg\"][\"f1-score\"]\n",
    "    })\n",
    "  \n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=chain_svm,\n",
    "        artifact_path=\"model_chain_linear_svm\",\n",
    "        registered_model_name=\"ClassificationchainandlinearSVM\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "abbcbbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF features: (1, 7126)\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF features:\", tfidf.transform(sample_title).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83359763",
   "metadata": {},
   "source": [
    "this was me , testing one of the models , which quite worked "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f67e597",
   "metadata": {},
   "source": [
    "i had to lower the thresshold , because we didnt took overview as a column , so the model didint hadnt much to learn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fd88cec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Genres: ['Action', 'Comedy', 'Crime', 'Drama']\n"
     ]
    }
   ],
   "source": [
    "# BR and Lr\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sample_title = [\"Rush Hour\"]\n",
    "\n",
    "sample_X = tfidf.transform(sample_title)\n",
    "\n",
    "probs = br_lr.predict_proba(sample_X)[0]\n",
    "\n",
    "threshold = 0.3\n",
    "\n",
    "predicted_genres = [\n",
    "    mlb.classes_[i]\n",
    "    for i, p in enumerate(probs)\n",
    "    if p >= threshold\n",
    "]\n",
    "\n",
    "print(\"Predicted Genres:\", predicted_genres)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb302f7",
   "metadata": {},
   "source": [
    "as u can see the model is performing good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "27e12bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Genres: [('Action', 'Adventure', 'Science Fiction')]\n"
     ]
    }
   ],
   "source": [
    "sample_title = [\"The Dark Knight\"]\n",
    "\n",
    "sample_X = tfidf.transform(sample_title)\n",
    "\n",
    "# Predict\n",
    "sample_pred = chain_svm.predict(sample_X)\n",
    "\n",
    "predicted_genres = mlb.inverse_transform(sample_pred)\n",
    "\n",
    "print(\"Predicted Genres:\", predicted_genres)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6e4b80",
   "metadata": {},
   "source": [
    "i had to do the same for CC+ SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd6d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Genres: ['Adventure', 'Drama', 'Science Fiction']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_title = [\"Interstellar\"]\n",
    "\n",
    "# Transform input  TF-IDF\n",
    "sample_X = tfidf.transform(sample_title)\n",
    "# SVM outputs decision scores, which are mapped to genres using a custom threshold:\n",
    "scores = chain_svm.decision_function(sample_X)[0]\n",
    "\n",
    "threshold = -0.3   # try -0.3, -0.5, -1.0 if needed\n",
    "\n",
    "# Convert scores to genre labels\n",
    "predicted_genres = [\n",
    "    mlb.classes_[i]\n",
    "    for i, score in enumerate(scores)\n",
    "    if score >= threshold\n",
    "]\n",
    "\n",
    "print(\"Predicted Genres:\", predicted_genres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "414f25eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chain_svm.pkl']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(chain_svm, 'chain_svm.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c97ee",
   "metadata": {},
   "source": [
    "as u can see classification chain is perfomring better than binary relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2154d2a3",
   "metadata": {},
   "source": [
    "we will be loading that model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
